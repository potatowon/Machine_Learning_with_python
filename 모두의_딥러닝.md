

# 01 ë¨¸ì‹ ëŸ¬ë‹ì˜ ê°œìš”
 - ğŸ’¡ supervised : learning with labeled examples (training set) `ì£¼ë¡œ ë°°ìš¸ë‚´ìš©`
<p align='center'><img src="https://user-images.githubusercontent.com/118495946/214555562-b7df5d97-b9e8-471a-9989-0a9dc50ae727.jpeg" width="600" height="300"/></p>
 -  ğŸ’¡ Unsupervised learning : un-labeled data
  - Google news grouping
  - Word clustering

## 01-1 types of supervised learning
1. ğŸ’¡ `regression` : prediction final exam score based on time spent (ì—°ì†ì ì¸ ê°’)
2. ğŸ’¡ `binart calssification` : pass/non-pass based on time spent ( 2ê°œì˜ ê°’)
3. ğŸ’¡ `multi-label classification` : Letter grade based on time spent ( ë¶ˆì—°ì†ì ì¸ ì—¬ëŸ¬ê°œì˜ ê°’)

# 02 ì„ í˜• íšŒê·€
ğŸ’¡ ëŒ€í‘œì ì¸ ì˜ˆì‹œë¡œ : prediction final exam score based on time spent ê°€ ìˆë‹¤ê³  í•˜ì <\br>
ê° `training dataset` ì„ ì²´í¬í•˜ê³  ì´ì™€ ê°€ì¥ ì˜ ë§ëŠ” ì„ í˜•ì‹ì„ ì°¾ëŠ” ê²ƒì´ ë¬¸ì œì´ë‹¤

## 02-1 (Linear) Hypothesis
### ìˆ˜ì‹
$$H(x) = Wx + b (W : ê°€ì¤‘ì¹˜, b: bias)$$
ê°€ì¤‘ì¹˜ì™€ ì ˆí¸ì„ ì¡°ì ˆí•˜ì—¬ ì ì ˆí•œ ì„ í˜• ë°©ì •ì‹ì„ ì°¾ëŠ”ë‹¤.

## 02-02 Cost function(1) : square
 ğŸ’¡ ëª¨ë¸ê³¼ ì‹¤ì œ ë°ì´í„° ê°’ì˜ ì°¨ì´
 - How fit the line to our (training) data
 - ì œê³±
$$(H(x) - y )^{2} = loss function $$
ì´ë•Œ $ y $ ëŠ” ì˜ˆì¸¡ ê°’
### ìˆ˜ì‹
$$cost = {1 over m} \Sigma \limit_{i=1}^{m} H(x^{(i)} - y^{(i)}) ^{2}$$



